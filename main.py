import asyncio
from contextlib import asynccontextmanager

from aiohttp import ClientResponseError
from fastapi import FastAPI, Header, Depends, HTTPException
from pydantic import ValidationError

from model import QuestionRequest, Res, Provider, A
import providers.manager as manager
from core import construct_res
import uvicorn
from database import init_database, close_database, get_db_session
from database.cache_service import query_cache_batch, save_cache_async
from sqlalchemy.ext.asyncio import AsyncSession

mgr = manager.ProvidersManager()


@asynccontextmanager
async def lifespan(_app: FastAPI):
    """
    åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†

    å¯åŠ¨æ—¶ï¼š
    1. åˆå§‹åŒ–æ•°æ®åº“è¿æ¥å’Œè¡¨ç»“æ„
    2. åˆå§‹åŒ–aiohttpä¼šè¯
    3. æ˜¾ç¤ºå¯ç”¨çš„é€‚é…å™¨åˆ—è¡¨

    å…³é—­æ—¶ï¼š
    1. å…³é—­aiohttpä¼šè¯
    2. å…³é—­æ•°æ®åº“è¿æ¥
    """
    print("æ­£åœ¨åˆå§‹åŒ–æ•°æ®åº“...")
    await init_database()
    print("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

    print("å½“å‰é€‚é…å™¨åˆ—è¡¨ï¼š", mgr.available_plugins())
    await manager.Providersbase.init_session()

    yield

    await manager.Providersbase.close_session()
    await close_database()
    print("åº”ç”¨å·²å…³é—­")


app = FastAPI(lifespan=lifespan)


def get_api_key(authorization: str = Header(...)):
    if not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="Invalid authorization header")
    token = authorization.split(" ", 1)[1]
    return token


MAX_CONCURRENT = 20


async def _call_adapter(ad, question, provider, sem: asyncio.Semaphore):
    """
    åœ¨ä¿¡å·é‡ä¿æŠ¤ä¸‹è°ƒç”¨å•ä¸ª providers.searchï¼Œæ•è·å¼‚å¸¸å¹¶è¿”å›ç»Ÿä¸€ç»“æ„ã€‚
    """
    async with sem:
        return await ad.search(question, provider)


@app.post("/v1/adapter-service/search")
async def search(
    _search_request: QuestionRequest,
    api_key: str = Depends(get_api_key),
    session: AsyncSession = Depends(get_db_session)
):
    """
    é¢˜ç›®æœç´¢æ¥å£

    æµç¨‹ï¼š
    1. æ‰¹é‡æŸ¥è¯¢ç¼“å­˜ï¼ˆä¸€æ¬¡æŸ¥è¯¢è·å–æ‰€æœ‰providerçš„ç¼“å­˜ï¼‰
    2. å¯¹äºæœ‰ç¼“å­˜çš„providerï¼š
       - å¦‚æœè¯·æ±‚ä¸­åŒ…å«è¯¥providerï¼Œä½¿ç”¨ç¼“å­˜ç­”æ¡ˆ
       - å¦‚æœè¯·æ±‚ä¸­ä¸åŒ…å«è¯¥providerï¼Œå¿½ç•¥ç¼“å­˜
    3. å¯¹äºæ²¡æœ‰ç¼“å­˜çš„providerï¼Œè°ƒç”¨å®é™…çš„adapteræŸ¥è¯¢
    4. å¼‚æ­¥å†™å…¥æ–°çš„ç­”æ¡ˆåˆ°ç¼“å­˜ï¼ˆä¸é˜»å¡å“åº”ï¼‰
    5. è¿”å›èšåˆç»“æœ

    Args:
        _search_request: æœç´¢è¯·æ±‚ï¼ŒåŒ…å«é¢˜ç›®å’Œprovideråˆ—è¡¨
        api_key: APIå¯†é’¥ï¼ˆç”¨äºé‰´æƒï¼‰
        session: æ•°æ®åº“ä¼šè¯ï¼ˆä¾èµ–æ³¨å…¥ï¼‰

    Returns:
        Res: èšåˆåçš„æœç´¢ç»“æœ
    """
    # 1. æ‰¹é‡æŸ¥è¯¢ç¼“å­˜
    cached_answers = await query_cache_batch(
        session=session,
        query=_search_request.query,
        providers=_search_request.providers
    )

    # 2. åˆ†ç¦»æœ‰ç¼“å­˜å’Œæ— ç¼“å­˜çš„provider
    providers_to_query = []  # éœ€è¦å®é™…æŸ¥è¯¢çš„provider
    answers_from_cache = []  # ä»ç¼“å­˜è·å–çš„ç­”æ¡ˆ
    requested_provider_names = {p.name for p in _search_request.providers}

    for provider in _search_request.providers:
        cached_answer = cached_answers.get(provider.name)

        if cached_answer is not None:
            # æœ‰ç¼“å­˜ï¼Œç›´æ¥ä½¿ç”¨
            print(f"ç¼“å­˜å‘½ä¸­: {provider.name}")
            answers_from_cache.append(cached_answer)
        else:
            # æ— ç¼“å­˜ï¼Œéœ€è¦æŸ¥è¯¢
            providers_to_query.append(provider)

    # 3. å¹¶å‘æŸ¥è¯¢æ²¡æœ‰ç¼“å­˜çš„provider
    sem = asyncio.Semaphore(MAX_CONCURRENT)
    tasks = []

    for provider in providers_to_query:
        adapter = mgr.get_adapter_achieve(provider.name)
        if adapter is None:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°é€‚é…å™¨ {provider.name}")
            continue

        # create_task ç«‹å³è°ƒåº¦ï¼Œä½†å®é™…å¹¶å‘ç”± sem æ§åˆ¶
        tasks.append(
            asyncio.create_task(
                _call_adapter(adapter, _search_request.query, provider, sem)
            )
        )

    # ç­‰å¾…æ‰€æœ‰æŸ¥è¯¢å®Œæˆ
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # 4. å¤„ç†æŸ¥è¯¢ç»“æœ
    answers_from_query = []  # ä»å®é™…æŸ¥è¯¢è·å–çš„ç­”æ¡ˆ
    provider_answer_pairs = []  # ç”¨äºå¼‚æ­¥å†™å…¥ç¼“å­˜çš„æ•°æ®

    for i, res in enumerate(results):
        provider = providers_to_query[i]

        if isinstance(res, Exception):
            # å‘ç”Ÿäº†æœªæ•è·çš„å¼‚å¸¸ï¼ˆç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼Œå› ä¸ºproviderå†…éƒ¨åº”è¯¥æ•è·æ‰€æœ‰å¼‚å¸¸ï¼‰
            print(f"âš ï¸  æœªæ•è·å¼‚å¸¸ [{provider.name}]: {type(res).__name__}: {res}")
            # åˆ›å»ºä¸€ä¸ªå¤±è´¥çš„ç­”æ¡ˆå¯¹è±¡
            error_answer = A(
                provider=provider.name,
                type=_search_request.query.type,
                success=False,
                error_type="unknown",
                error_message=f"æœªæ•è·å¼‚å¸¸: {str(res)}"
            )
            answers_from_query.append(error_answer)
        else:
            # æ­£å¸¸è¿”å›çš„ A å¯¹è±¡
            if res.success:
                print(f"âœ… æˆåŠŸ [{res.provider}]: {res.choice or res.text or res.judgement}")
                # åªæœ‰æˆåŠŸçš„ç­”æ¡ˆæ‰å†™å…¥ç¼“å­˜
                provider_answer_pairs.append((provider, res))
            else:
                print(f"âŒ å¤±è´¥ [{res.provider}]: {res.error_type} - {res.error_message}")

            answers_from_query.append(res)

    # 5. åˆå¹¶ç¼“å­˜ç­”æ¡ˆå’ŒæŸ¥è¯¢ç­”æ¡ˆ
    all_answers = answers_from_cache + answers_from_query

    # 6. å¼‚æ­¥å†™å…¥ç¼“å­˜ï¼ˆä¸é˜»å¡å“åº”ï¼‰
    if provider_answer_pairs:
        asyncio.create_task(
            save_cache_async(_search_request.query, provider_answer_pairs)
        )

    # 7. æ„é€ å¹¶è¿”å›å“åº”
    result = construct_res(_search_request.query, all_answers)

    # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š æŸ¥è¯¢ç»Ÿè®¡:")
    print(f"   æ€»provideræ•°: {result.total_providers}")
    print(f"   âœ… æˆåŠŸ: {result.successful_providers}")
    print(f"   âŒ å¤±è´¥: {result.failed_providers}")
    print(f"   æœ€ç»ˆç­”æ¡ˆ: {result.unified_answer.answerKeyText or result.unified_answer.answerText or 'æ— '}")

    return result


if __name__ == '__main__':
    uvicorn.run('demo:app', host="127.0.0.1", port=8060, log_level='info')
    # uvicorn demo:app --host 0.0.0.0 --port 8060 --workers 4 --log-level info
